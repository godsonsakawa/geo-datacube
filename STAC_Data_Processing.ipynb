{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import shape          #AOI\n",
    "import pystac_client                        #STAC API\n",
    "from datetime import datetime, timedelta    #Time Range\n",
    "import planetary_computer                   #Cloud-based data access\n",
    "import rioxarray as rxr                     #loading raster data & reprojecting\n",
    "import xarray as xr                         #Intergrate dataset into datacube\n",
    "import matplotlib.pyplot as plt             #Visualization\n",
    "import dask                                 #Lazy Loading\n",
    "import cdsapi\n",
    "import geopandas as gpd   #loading vector data\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOI Bounding Box: 36.306872504019424, -0.7423752404067301, 36.45206844566468, -0.5952725839718056\n"
     ]
    }
   ],
   "source": [
    "# Given AOI\n",
    "aoi_geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": [\n",
    "        {\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {},\n",
    "            \"geometry\": {\n",
    "                \"coordinates\": [[\n",
    "                    [36.306872504019424, -0.5952725839718056],\n",
    "                    [36.306872504019424, -0.7423752404067301],\n",
    "                    [36.45206844566468, -0.7423752404067301],\n",
    "                    [36.45206844566468, -0.5952725839718056],\n",
    "                    [36.306872504019424, -0.5952725839718056]\n",
    "                ]],\n",
    "                \"type\": \"Polygon\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to Bounding Box (min_lon, min_lat, max_lon, max_lat)\n",
    "aoi_geometry = shape(aoi_geojson[\"features\"][0][\"geometry\"])\n",
    "min_lon, min_lat, max_lon, max_lat = aoi_geometry.bounds\n",
    "print(f\"AOI Bounding Box: {min_lon}, {min_lat}, {max_lon}, {max_lat}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Stac API & Print all collections, specify Time Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching data from 2024-11-30 to 2025-02-28\n"
     ]
    }
   ],
   "source": [
    "# Connect to a public STAC API \n",
    "STAC_API_URLS = [\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    \"https://earth-search.aws.element84.com/v1\"\n",
    "]\n",
    "\n",
    "os.environ[\"AWS_NO_SIGN_REQUEST\"] = \"YES\"\n",
    "\n",
    "# Initialize STAC client\n",
    "client = pystac_client.Client.open(STAC_API_URLS[1])\n",
    "\n",
    "# Time Range: Last 3 months\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=90)\n",
    "date_range = f\"{start_date.date()}/{end_date.date()}\"\n",
    "\n",
    "print(f\"Searching data from {start_date.date()} to {end_date.date()}\")\n",
    "\n",
    "# Print available collections\n",
    "#collections = client.get_all_collections()\n",
    "#print(\"Available Collections:\", [c.id for c in collections])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the STAC API for the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Query Sentinel-1 (VV, VH - Radar Backscatter) data & Load the Data as raster arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 Sentinel-1 items\n",
      "Total VV Images: 7\n",
      "Total VH Images: 7\n",
      "All VV & VH rasters loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Query Sentinel-1 GRD for VV & VH (Radar)\n",
    "s1_search = client.search(\n",
    "    collections=[\"sentinel-1-grd\"], bbox=[min_lon, min_lat, max_lon, max_lat], datetime=date_range\n",
    ")\n",
    "\n",
    "# Display results for Sentinel-1 GRD for VV & VH\n",
    "s1_items = list(s1_search.items())\n",
    "print(f\"Found {len(s1_items)} Sentinel-1 items\")\n",
    "\n",
    "# Sign URLs for Direct Access\n",
    "s1_items = [planetary_computer.sign(item).assets for item in s1_items]\n",
    "\n",
    "# Extract VV & VH Polarization URLs\n",
    "vv_links = [item[\"vv\"].href for item in s1_items if \"vv\" in item]\n",
    "vh_links = [item[\"vh\"].href for item in s1_items if \"vh\" in item]\n",
    "\n",
    "print(f\"Total VV Images: {len(vv_links)}\")\n",
    "print(f\"Total VH Images: {len(vh_links)}\")\n",
    "\n",
    "# Load VV Polarization as Raster\n",
    "vv_rasters = [rxr.open_rasterio(vv, masked=True) for vv in vv_links]\n",
    "vh_rasters = [rxr.open_rasterio(vh, masked=True) for vh in vh_links]\n",
    "\n",
    "print(\"All VV & VH rasters loaded successfully.\")\n",
    "\n",
    "# Plot Sample (First VV & VH Image)  for #testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Query Sentinel-2 (NDVI - Vegetation Health) data & Load the Data as raster arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 Sentinel-2 L2A items\n",
      "All NDVI rasters loaded (lazily) successfully.\n"
     ]
    }
   ],
   "source": [
    "# Query Sentinel-2 L2A Data\n",
    "s2_search = client.search(\n",
    "    collections=[\"sentinel-2-l2a\"], bbox=[min_lon, min_lat, max_lon, max_lat], datetime=date_range\n",
    ")\n",
    "\n",
    "# Extract Items\n",
    "s2_items = list(s2_search.items())\n",
    "print(f\"Found {len(s2_items)} Sentinel-2 L2A items\")\n",
    "\n",
    "# Ensure we have at least one item\n",
    "if not s2_items:\n",
    "    raise ValueError(\"No Sentinel-2 L2A data found for the given AOI and date range.\")\n",
    "\n",
    "# Authenticate all items for cloud access\n",
    "s2_items = [planetary_computer.sign(item) for item in s2_items]\n",
    "\n",
    "\n",
    "# Load all available B04 (Red) and B08 (NIR) bands\n",
    "# Open bands with chunking for lazy loading\n",
    "B4_rasters = [\n",
    "    rxr.open_rasterio(item.assets[\"red\"].href, masked=True, chunks={'x':1024, 'y':1024}).squeeze()\n",
    "    for item in s2_items\n",
    "]\n",
    "B8_rasters = [\n",
    "    rxr.open_rasterio(item.assets[\"nir\"].href, masked=True, chunks={'x':1024, 'y':1024}).squeeze()\n",
    "    for item in s2_items\n",
    "]\n",
    "\n",
    "# Compute NDVI lazily\n",
    "NDVI_rasters = [ (nir - red) / (nir + red) for red, nir in zip(B4_rasters, B8_rasters) ]\n",
    "\n",
    "print(\"All NDVI rasters loaded (lazily) successfully.\")\n",
    "# Plot a sample NDVI image (First available) for #testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Query (Temperature - Climatic Variations) data & Load the Data as raster arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 20:28:23,904 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-02-28 20:28:23,905 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n",
      "2025-02-28 20:28:24,781 INFO Request ID is 3f026a15-9c6b-455c-b0f1-7fb6c7ba5446\n",
      "2025-02-28 20:28:24,995 INFO status has been updated to accepted\n",
      "2025-02-28 20:28:33,952 INFO status has been updated to running\n",
      "2025-02-28 20:29:00,558 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e60796fc2644d15ad61f54a6c090412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5128b8e2eb150f61cfdeb693afc2732a.nc:   0%|          | 0.00/31.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'era5_temperature.nc'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define bounding box and time range\n",
    "# ERA5 expects [North, West, South, East]\n",
    "bbox = [-0.5952725839718056, 36.306872504019424, -0.7423752404067301, 36.45206844566468] \n",
    "start_date = \"2024-12-01\"  # December 1, 2024\n",
    "end_date = \"2025-02-28\"    # February 28, 2025\n",
    "date_range = f\"{start_date}/{end_date}\"\n",
    "\n",
    "# Initialize the CDS API client\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Download ERA5 daily 2m temperature data\n",
    "c.retrieve(\n",
    "    \"reanalysis-era5-single-levels\",\n",
    "    {\n",
    "        \"variable\": \"2m_temperature\",\n",
    "        \"product_type\": \"reanalysis\",\n",
    "        \"year\": [\"2024\", \"2025\"],  \n",
    "        \"month\": [\"12\", \"01\", \"02\"],  # Last 3 monthsa\n",
    "        \"day\": [str(i).zfill(2) for i in range(1, 32)],  # All days\n",
    "        \"time\": \"12:00\",\n",
    "        \"format\": \"netcdf\",\n",
    "        \"area\": bbox,  # Full AOI region\n",
    "    },\n",
    "    \"era5_temperature.nc\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ERA5 Temperature Raster ==========\n",
      "Date Range: 2024-12-01/2025-02-28\n",
      "Raster Shape (time, lat, lon): (145, 1, 1)\n",
      "<xarray.DataArray (band: 145, y: 1, x: 1)> Size: 580B\n",
      "[145 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * band         (band) int64 1kB 1 2 3 4 5 6 7 ... 139 140 141 142 143 144 145\n",
      "  * x            (x) float64 8B 36.31\n",
      "  * y            (y) float64 8B -0.743\n",
      "    spatial_ref  int64 8B 0\n",
      "Attributes:\n",
      "    scale_factor:  1.0\n",
      "    add_offset:    0.0\n",
      "    long_name:     t2m\n"
     ]
    }
   ],
   "source": [
    "# Load the NetCDF file using xarray\n",
    "# Use the netCDF4 engine explicitly\n",
    "era5_data = xr.open_dataset(\"era5_temperature.nc\", engine=\"netcdf4\")\n",
    "\n",
    "# Assuming 'temperature_raster' is your xarray.DataArray\n",
    "temperature_raster = era5_data[\"t2m\"] - 273.15  # Convert to Celsius\n",
    "\n",
    "# Define the affine transform for your raster data\n",
    "# Here we use the origin (longitude, latitude) and the pixel size (spacing between pixels).\n",
    "# Adjust the parameters based on your data’s actual spatial characteristics.\n",
    "transform = rio.transform.from_origin(west=36.31, north=-0.743, xsize=0.5, ysize=0.5)\n",
    "\n",
    "# Now you can write the raster to a GeoTIFF with the correct georeferencing information\n",
    "temperature_raster.rio.write_transform(transform, inplace=True)\n",
    "\n",
    "# Save the data as a GeoTIFF file\n",
    "temperature_raster.rio.to_raster(\"temperature_raster.tif\")\n",
    "\n",
    "# Open the raster using rioxarray\n",
    "temperature_raster = rxr.open_rasterio(\"temperature_raster.tif\")\n",
    "\n",
    "# Print metadata and shape\n",
    "print(\"========== ERA5 Temperature Raster ==========\")\n",
    "print(f\"Date Range: {date_range}\")\n",
    "print(\"Raster Shape (time, lat, lon):\", temperature_raster.shape)\n",
    "\n",
    "print(temperature_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Query (Elevation - Terrain Impact)data & Load the Data as raster arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation data saved as elevation.tif\n",
      "<xarray.DataArray 'Elevation' (band: 1, y: 530, x: 523)> Size: 1MB\n",
      "[277190 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * band         (band) int64 8B 1\n",
      "  * x            (x) float64 4kB 36.31 36.31 36.31 36.31 ... 36.45 36.45 36.45\n",
      "  * y            (y) float64 4kB -0.5953 -0.5956 -0.5958 ... -0.7419 -0.7422\n",
      "    spatial_ref  int64 8B 0\n",
      "Attributes:\n",
      "    AREA_OR_POINT:  Area\n",
      "    scale_factor:   1.0\n",
      "    add_offset:     0.0\n"
     ]
    }
   ],
   "source": [
    "# OpenTopography API Endpoint\n",
    "opentopo_url = \"https://portal.opentopography.org/API/globaldem\"\n",
    "\n",
    "# Define AOI Bounding Box\n",
    "params = {\n",
    "    \"demtype\": \"SRTMGL1\",  # SRTMGL1, COP30, or COP90\n",
    "    \"west\": 36.306872,      # Min Longitude\n",
    "    \"south\": -0.742375,     # Min Latitude\n",
    "    \"east\": 36.452068,      # Max Longitude\n",
    "    \"north\": -0.595272,     # Max Latitude\n",
    "    \"outputFormat\": \"GTiff\",  # GeoTIFF format\n",
    "    \"API_Key\": \"5a856dfd43a0f226322ccd13bb7b9654\"  # Load API key from environment variable\n",
    "}\n",
    "\n",
    "# Make API request\n",
    "response = requests.get(opentopo_url, params=params)\n",
    "\n",
    "# Check if request was successful\n",
    "if response.status_code == 200:\n",
    "    # Save the GeoTIFF file\n",
    "    dem_path = \"elevation.tif\"\n",
    "    with open(dem_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Elevation data saved as {dem_path}\")\n",
    "else:\n",
    "    raise Exception(f\"Failed to fetch elevation data: {response.text}\")\n",
    "\n",
    "# Load the GeoTIFF as a raster array\n",
    "elevation_raster = rxr.open_rasterio(dem_path, masked=True)\n",
    "elevation_raster.name = \"Elevation\"\n",
    "\n",
    "# Print metadata\n",
    "print(elevation_raster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject the Data to a Common CRS & Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define target CRS\n",
    "target_crs = \"EPSG:4326\"\n",
    "\n",
    "# Ensure CRS is set correctly before reprojecting\n",
    "for vv in vv_rasters:\n",
    "    vv.rio.write_crs(\"EPSG:4326\", inplace=True)  # Adjust if different\n",
    "\n",
    "for vh in vh_rasters:\n",
    "    vh.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "# Reproject using nearest resampling & chunking\n",
    "vv_reprojected = [vv.rio.reproject(target_crs, resampling=rio.enums.Resampling.nearest, blockxsize=1024, blockysize=1024) for vv in vv_rasters]\n",
    "vh_reprojected = [vh.rio.reproject(target_crs, resampling=rio.enums.Resampling.nearest, blockxsize=1024, blockysize=1024) for vh in vh_rasters]\n",
    "\n",
    "print(\"✅ Reprojection completed for VV & VH rasters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate the datasets into a Datacube & save it into a portable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the Datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
